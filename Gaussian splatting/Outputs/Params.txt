âœ… FINAL METRICS & EVALUATION CHECKLIST
(2D â†’ 2.5D / 3D using Gaussian Splatting)
1ï¸âƒ£ Image Quality Metrics (MANDATORY â€“ instant reject if missing)
â˜ PSNR (dB)
Novel view synthesis
Mean Â± Std across test views
Same camera poses for all methods
â˜ SSIM
Window size stated
Averaged over all test images
â˜ LPIPS
Network used: Alex / VGG (must be stated)
Lower is better (explicitly mentioned)
ğŸ“Œ Report format
Method
PSNR â†‘
SSIM â†‘
LPIPS â†“
2ï¸âƒ£ Depth / Geometry Consistency Metrics (CRITICAL for your claim)
â˜ Depth RMSE
â˜ Absolute Relative Error (AbsRel)
â˜ Scale-Invariant Error (Si-log)
â˜ Depth GT source clearly stated
Real GT depth OR
COLMAP pseudo-depth (explicitly acknowledged)
ğŸ“Œ If NO depth metrics â†’ your â€œ2.5D/3Dâ€ claim is invalid.
3ï¸âƒ£ Rendering & Computational Performance (Gaussian Splatting â‰  NeRF)
â˜ Rendering FPS
Resolution specified
GPU model stated
â˜ Training time
Total optimization time
Iterations / epochs mentioned
â˜ Memory usage (VRAM in GB)
ğŸ“Œ Reviewers LOVE efficiency numbers.
4ï¸âƒ£ Representation Quality (Strong but Optional)
â˜ Number of Gaussians
â˜ Gaussian pruning ratio
â˜ Scene density vs quality trade-off
ğŸ“Œ This makes your work look engineered, not hacked.
5ï¸âƒ£ Baseline Comparison (ABSOLUTE REQUIREMENT)
â˜ COLMAP + Mesh Rendering
â˜ Vanilla NeRF
â˜ Official 3D Gaussian Splatting
â˜ Same dataset, same train/test split
ğŸ“Œ Even one missing baseline = high rejection risk
6ï¸âƒ£ Ablation Studies (SMALL but NON-NEGOTIABLE)
â˜ With vs without depth guidance
â˜ Sparse vs dense views
â˜ Gaussian count vs quality
ğŸ“Œ Minimum: 1 table + 1 qualitative figure
7ï¸âƒ£ Qualitative Results (SUPPORTING, not replacing metrics)
â˜ Novel view renders (side-by-side)
â˜ Failure cases shown
â˜ Same camera viewpoints for all methods
ğŸš« Do NOT rely only on visuals â€” that screams â€œdemo paperâ€.
8ï¸âƒ£ Dataset & Protocol Transparency
â˜ Dataset name + size
â˜ Train / test split explained
â˜ Number of input views stated
â˜ Camera calibration source
ğŸ“Œ Missing protocol details = reviewer distrust.
9ï¸âƒ£ Claims â†” Metrics Consistency (MOST COMMON REJECTION)
â˜ Every claim backed by a metric
â˜ No words like â€œsignificant improvementâ€ without numbers
â˜ No claim of â€œtrue 3D reconstructionâ€ without GT geometry
ğŸ”Ÿ Paper-Ready Sanity Check
â˜ Tables use â†‘ â†“ arrows correctly
â˜ Units mentioned everywhere
â˜ Mean Â± Std reported
â˜ Reproducibility section included