{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# üéØ 2D Video ‚Üí 3D Gaussian Splatting Pipeline (Fixed & Enhanced)\n",
        "\n",
        "This notebook converts a 2D video into a 3D Gaussian Splatting model (.ply) and extracts specific objects using bounding boxes.\n",
        "\n",
        "**Pipeline Overview:**\n",
        "1. ‚úÖ Setup Environment\n",
        "2. ‚úÖ Upload & Prepare Video\n",
        "3. ‚úÖ Extract Frames\n",
        "4. ‚úÖ Run COLMAP (Camera Pose Estimation)\n",
        "5. ‚úÖ Train Gaussian Splatting Model\n",
        "6. ‚úÖ **Explore Scene & Find Perfect Bounding Box**\n",
        "7. ‚úÖ **Export Cropped Object as .ply**\n",
        "8. ‚úÖ Download Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jwrTAkg78jL"
      },
      "source": [
        "---\n",
        "## Step 1: Check GPU & Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYeHBQin78jL"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gez1YwT878jM"
      },
      "outputs": [],
      "source": [
        "# Install system dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y colmap ffmpeg imagemagick libgl1-mesa-glx libglib2.0-0 2>/dev/null | tail -5\n",
        "print(\"‚úÖ System dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UKp3nf378jM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "# Clone Gaussian Splatting if not already cloned\n",
        "if not os.path.exists('/content/gaussian-splatting'):\n",
        "    !git clone https://github.com/graphdeco-inria/gaussian-splatting --recursive -q\n",
        "    print(\"‚úÖ Gaussian Splatting repo cloned\")\n",
        "else:\n",
        "    print(\"‚úÖ Gaussian Splatting repo already exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAXWZnbR78jN"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/gaussian-splatting')\n",
        "\n",
        "# Install Python dependencies\n",
        "!pip install -q plyfile==0.8.1 tqdm\n",
        "\n",
        "# Install submodules (these require CUDA)\n",
        "!pip install -q submodules/diff-gaussian-rasterization\n",
        "!pip install -q submodules/simple-knn\n",
        "\n",
        "print(\"‚úÖ Python dependencies installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "319SCyt-78jN"
      },
      "source": [
        "---\n",
        "## Step 2: Upload & Prepare Your Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEjlN0Qw78jN"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"üìÅ Upload your video file (MP4, MOV, AVI supported):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "video_filename = list(uploaded.keys())[0]\n",
        "# Corrected video_path to reflect the actual upload location\n",
        "video_path = f\"/content/gaussian-splatting/{video_filename}\"\n",
        "\n",
        "''' # Verify\n",
        "size_mb = os.path.getsize(video_path) / (1024*1024)\n",
        "print(f\"‚úÖ Uploaded: {video_filename} ({size_mb:.1f} MB)\") '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qisrVxR78jO"
      },
      "outputs": [],
      "source": [
        "# ------ OR: use a direct URL instead of uploading ------\n",
        "# Uncomment and edit the lines below if you want to download from a URL\n",
        "\n",
        "# video_url = \"https://your-video-url-here.mp4\"\n",
        "# video_filename = \"input_video.mp4\"\n",
        "# video_path = f\"/content/{video_filename}\"\n",
        "# !wget -q -O {video_path} \"{video_url}\"\n",
        "# print(f\"‚úÖ Downloaded: {video_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7upobFGN78jO"
      },
      "source": [
        "---\n",
        "## Step 3: Extract Frames from Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65H-PE8S78jO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "project_name = \"my_scene\"      # Change this to name your project\n",
        "fps          = 5               # Frames per second to extract\n",
        "                               # Use 2-5 for long videos, 10 for short/detailed ones\n",
        "max_dimension = 1920           # Resize longest side to this (keeps aspect ratio)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "base_dir  = f\"/content/data/{project_name}\"\n",
        "input_dir = f\"{base_dir}/input\"\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "# Extract frames ‚Äî scale preserving aspect ratio, high quality JPEG\n",
        "!ffmpeg -y -i \"{video_path}\" \\\n",
        "    -vf \"fps={fps},scale='if(gt(iw,ih),{max_dimension},-2)':'if(gt(iw,ih),-2,{max_dimension})'\" \\\n",
        "    -qscale:v 2 \"{input_dir}/%04d.jpg\" 2>&1 | tail -5\n",
        "\n",
        "frames = sorted(glob.glob(f\"{input_dir}/*.jpg\"))\n",
        "print(f\"\\n‚úÖ Extracted {len(frames)} frames into {input_dir}\")\n",
        "print(\"   Tip: Aim for 100‚Äì400 frames. Too few = poor reconstruction, too many = slow.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-p7wrf378jP"
      },
      "source": [
        "---\n",
        "## Step 4: Run COLMAP (Structure-from-Motion)\n",
        "COLMAP estimates where the camera was for each frame ‚Äî essential for 3D reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeD2DMxm78jP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/gaussian-splatting')\n",
        "\n",
        "# Set offscreen rendering for headless Colab environment\n",
        "os.environ['QT_QPA_PLATFORM'] = 'offscreen'\n",
        "\n",
        "print(\"üîÑ Running COLMAP... (this may take 5‚Äì20 minutes depending on frame count)\")\n",
        "\n",
        "!python convert.py -s /content/data/{project_name} --no_gpu\n",
        "\n",
        "print(\"\\n‚úÖ COLMAP complete!\")\n",
        "\n",
        "# Verify COLMAP outputs\n",
        "sparse_dir = f\"/content/data/{project_name}/sparse/0\"\n",
        "if os.path.exists(sparse_dir):\n",
        "    files_found = os.listdir(sparse_dir)\n",
        "    print(f\"   COLMAP sparse model: {files_found}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  WARNING: Sparse directory not found. COLMAP may have failed.\")\n",
        "    print(\"   Try: reducing fps, ensuring the video has enough texture/detail,\")\n",
        "    print(\"   or using a shorter/simpler video.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "631NTh2l78jP"
      },
      "source": [
        "---\n",
        "## Step 5: Train Gaussian Splatting Model\n",
        "> ‚è± Estimated time: **~10 min** for 7000 iterations, **~30 min** for 30000 iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8OJSsJP78jP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/gaussian-splatting')\n",
        "\n",
        "# ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "iterations       = 30000   # 7000 = fast/preview | 30000 = high quality\n",
        "output_model_dir = f\"/content/output/{project_name}\"\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "os.makedirs(output_model_dir, exist_ok=True)\n",
        "\n",
        "print(f\"üîÑ Training for {iterations} iterations...\")\n",
        "\n",
        "!python train.py \\\n",
        "    -s /content/data/{project_name} \\\n",
        "    -m {output_model_dir} \\\n",
        "    --iterations {iterations} \\\n",
        "    --test_iterations {iterations} \\\n",
        "    --save_iterations {iterations}\n",
        "\n",
        "print(f\"\\n‚úÖ Training complete! Model saved to: {output_model_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4sJZPbp78jQ"
      },
      "outputs": [],
      "source": [
        "# Verify point cloud output\n",
        "point_cloud_path = f\"{output_model_dir}/point_cloud/iteration_{iterations}/point_cloud.ply\"\n",
        "\n",
        "if os.path.exists(point_cloud_path):\n",
        "    size_mb = os.path.getsize(point_cloud_path) / (1024*1024)\n",
        "    print(f\"‚úÖ Point cloud found: {point_cloud_path}\")\n",
        "    print(f\"   File size: {size_mb:.2f} MB\")\n",
        "else:\n",
        "    print(\"‚ùå Point cloud not found. Check training output for errors.\")\n",
        "    !find {output_model_dir} -name \"*.ply\" 2>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "g30yg3qsa522"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2xhdIyz78jQ"
      },
      "source": [
        "---\n",
        "## Step 6: üîç Explore Scene & Find the Perfect Bounding Box\n",
        "\n",
        "This is the key step for cropping. We'll:\n",
        "1. Load the full point cloud\n",
        "2. Print scene statistics (min/max XYZ, centroid)\n",
        "3. Visualize the point distribution per axis\n",
        "4. Give you an interactive way to tune bounding box values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJTrCvfg78jQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from plyfile import PlyData\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from IPython.display import display\n",
        "\n",
        "# ‚îÄ‚îÄ Load point cloud ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def load_ply_numpy(path):\n",
        "    \"\"\"Load PLY file and return positions as numpy array.\"\"\"\n",
        "    ply_data = PlyData.read(path)\n",
        "    vertex = ply_data['vertex']\n",
        "    x = np.array(vertex['x'])\n",
        "    y = np.array(vertex['y'])\n",
        "    z = np.array(vertex['z'])\n",
        "    positions = np.stack([x, y, z], axis=1)\n",
        "    return positions, ply_data\n",
        "\n",
        "positions, raw_ply = load_ply_numpy(point_cloud_path)\n",
        "N = len(positions)\n",
        "print(f\"‚úÖ Loaded {N:,} Gaussians from point cloud\")\n",
        "\n",
        "# ‚îÄ‚îÄ Scene statistics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "p_min  = positions.min(axis=0)\n",
        "p_max  = positions.max(axis=0)\n",
        "p_mean = positions.mean(axis=0)\n",
        "p_std  = positions.std(axis=0)\n",
        "\n",
        "# Percentile-based (robust to outliers)\n",
        "p_05  = np.percentile(positions, 5,  axis=0)\n",
        "p_95  = np.percentile(positions, 95, axis=0)\n",
        "p_10  = np.percentile(positions, 10, axis=0)\n",
        "p_90  = np.percentile(positions, 90, axis=0)\n",
        "p_25  = np.percentile(positions, 25, axis=0)\n",
        "p_75  = np.percentile(positions, 75, axis=0)\n",
        "\n",
        "print(\"\\n\" + \"=\"*55)\n",
        "print(\"         SCENE BOUNDING BOX ANALYSIS\")\n",
        "print(\"=\"*55)\n",
        "print(f\"  Total Gaussians : {N:,}\")\n",
        "print(f\"{'Metric':<12}  {'X':>10}  {'Y':>10}  {'Z':>10}\")\n",
        "print(\"-\"*45)\n",
        "print(f\"{'Min':<12}  {p_min[0]:>10.4f}  {p_min[1]:>10.4f}  {p_min[2]:>10.4f}\")\n",
        "print(f\"{'5th pct':<12}  {p_05[0]:>10.4f}  {p_05[1]:>10.4f}  {p_05[2]:>10.4f}\")\n",
        "print(f\"{'10th pct':<12}  {p_10[0]:>10.4f}  {p_10[1]:>10.4f}  {p_10[2]:>10.4f}\")\n",
        "print(f\"{'25th pct':<12}  {p_25[0]:>10.4f}  {p_25[1]:>10.4f}  {p_25[2]:>10.4f}\")\n",
        "print(f\"{'Mean':<12}  {p_mean[0]:>10.4f}  {p_mean[1]:>10.4f}  {p_mean[2]:>10.4f}\")\n",
        "print(f\"{'75th pct':<12}  {p_75[0]:>10.4f}  {p_75[1]:>10.4f}  {p_75[2]:>10.4f}\")\n",
        "print(f\"{'90th pct':<12}  {p_90[0]:>10.4f}  {p_90[1]:>10.4f}  {p_90[2]:>10.4f}\")\n",
        "print(f\"{'95th pct':<12}  {p_95[0]:>10.4f}  {p_95[1]:>10.4f}  {p_95[2]:>10.4f}\"check Step 6 stats)\n",
        "print(f\"{'Max':<12}  {p_max[0]:>10.4f}  {p_max[1]:>10.4f}  {p_max[2]:>10.4f}\")\n",
        "print(f\"{'Std Dev':<12}  {p_std[0]:>10.4f}  {p_std[1]:>10.4f}  {p_std[2]:>10.4f}\")\n",
        "print(\"=\"*55)\n",
        "\n",
        "print(\"\\nüí° SUGGESTED starting bounding boxes:\")\n",
        "print(f\"   Tight (10th‚Äì90th pct)  ‚Üí min={np.round(p_10,3).tolist()}, max={np.round(p_90,3).tolist()}\")\n",
        "print(f\"   Medium (5th‚Äì95th pct)  ‚Üí min={np.round(p_05,3).tolist()}, max={np.round(p_95,3).tolist()}\")\n",
        "print(f\"   Centred (mean ¬± 1 std) ‚Üí min={np.round(p_mean-p_std,3).tolist()}, max={np.round(p_mean+p_std,3).tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbiuOlWP78jQ"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ Visualise point distribution per axis ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "axis_names = ['X', 'Y', 'Z']\n",
        "colors = ['#e74c3c', '#2ecc71', '#3498db']\n",
        "\n",
        "for i, (ax, name, color) in enumerate(zip(axes, axis_names, colors)):\n",
        "    ax.hist(positions[:, i], bins=100, color=color, alpha=0.75, edgecolor='none')\n",
        "    ax.axvline(p_10[i],  color='orange', linestyle='--', linewidth=1.5, label='10th pct')\n",
        "    ax.axvline(p_90[i],  color='orange', linestyle='--', linewidth=1.5, label='90th pct')\n",
        "    ax.axvline(p_mean[i], color='white', linestyle='-',  linewidth=2, label='mean')\n",
        "    ax.set_title(f'{name} Axis Distribution', color='white', fontsize=13)\n",
        "    ax.set_xlabel('Position', color='white')\n",
        "    ax.set_ylabel('Count', color='white')\n",
        "    ax.tick_params(colors='white')\n",
        "    ax.set_facecolor('#1a1a2e')\n",
        "    ax.legend(fontsize=8)\n",
        "\n",
        "fig.patch.set_facecolor('#0f0f1a')\n",
        "plt.suptitle('Point Cloud Distribution per Axis\\n(dashed = 10th/90th percentile)',\n",
        "             color='white', fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/axis_distribution.png', dpi=120, bbox_inches='tight',\n",
        "            facecolor='#0f0f1a')\n",
        "plt.show()\n",
        "print(\"‚úÖ Histogram saved to /content/axis_distribution.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XnmrBju78jQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from plyfile import PlyData\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from IPython.display import display\n",
        "\n",
        "# ‚îÄ‚îÄ 3D scatter preview (sampled for speed) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "sample_n = min(20000, N)  # sample up to 20k points for plotting\n",
        "idx = np.random.choice(N, sample_n, replace=False)\n",
        "pts = positions[idx]\n",
        "\n",
        "# Colour by Z height for easy orientation\n",
        "z_norm = (pts[:, 2] - pts[:, 2].min()) / (np.ptp(pts[:, 2]) + 1e-8)\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "views = [(20, 45, 'Perspective'), (0, 0, 'XY (top)'), (0, 90, 'XZ (front)'), (90, 0, 'YZ (side)')]\n",
        "\n",
        "for k, (elev, azim, title) in enumerate(views):\n",
        "    ax = fig.add_subplot(1, 4, k+1, projection='3d')\n",
        "    ax.scatter(pts[:,0], pts[:,1], pts[:,2],\n",
        "               c=z_norm, cmap='plasma', s=0.3, alpha=0.6)\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "    ax.set_title(title, color='white', fontsize=10)\n",
        "    ax.set_facecolor('#1a1a2e')\n",
        "    ax.tick_params(colors='gray', labelsize=6)\n",
        "    ax.set_xlabel('X', color='gray', fontsize=7)\n",
        "    ax.set_ylabel('Y', color='gray', fontsize=7)\n",
        "    ax.set_zlabel('Z', color='gray', fontsize=7)\n",
        "\n",
        "fig.patch.set_facecolor('#0f0f1a')\n",
        "plt.suptitle(f'3D Point Cloud Preview ({sample_n:,} sampled points)',\n",
        "             color='white', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/point_cloud_3d_preview.png', dpi=120, bbox_inches='tight',\n",
        "            facecolor='#0f0f1a')\n",
        "plt.show()\n",
        "print(\"‚úÖ 3D preview saved to /content/point_cloud_3d_preview.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1lGRKUp78jQ"
      },
      "source": [
        "---\n",
        "## Step 7: üì¶ Export Cropped Object as .ply\n",
        "\n",
        "### How to find the perfect bounding box values:\n",
        "\n",
        "1. **Look at the histograms above** ‚Äî find where your target object lives vs. background noise\n",
        "2. **Use the suggested ranges** printed in Step 6 as a starting point\n",
        "3. **Check the 3D views** ‚Äî each view shows a different angle:\n",
        "   - `XY (top)` = bird's eye\n",
        "   - `XZ (front)` = front face\n",
        "   - `YZ (side)` = side profile\n",
        "4. **Start wide, go narrow** ‚Äî begin with the 5th‚Äì95th percentile range, then tighten\n",
        "5. **Check the Gaussian count** printed after each crop ‚Äî a good crop retains meaningful density\n",
        "\n",
        "**Coordinate system in Gaussian Splatting:**\n",
        "- `X` = left/right\n",
        "- `Y` = up/down (sometimes inverted ‚Äî check 3D view)\n",
        "- `Z` = depth (forward/backward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qumDm-WP78jR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from plyfile import PlyData, PlyElement\n",
        "import os\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "#  ‚úÖÔ∏è  SET YOUR BOUNDING BOX HERE\n",
        "#     Use the statistics & plots from Step 6 to guide you.\n",
        "#     Start with the 'Tight' suggestion and adjust from there.\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "bbox_min = np.array([-3.749, -1.847, 5.221])   # ‚Üê edit these three values\n",
        "bbox_max = np.array([3.346, 4.992, 10.239])   # ‚Üê edit these three values\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "output_name = \"cropped_object.ply\"         # Output filename\n",
        "output_path = f\"/content/{output_name}\"\n",
        "\n",
        "# ‚ïê‚ïê Filtering function ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "def crop_gaussians(ply_data, bbox_min, bbox_max, output_path):\n",
        "    \"\"\"\n",
        "    Crops a Gaussian Splatting PLY file to a bounding box.\n",
        "    Preserves ALL original vertex properties (SH, opacity, scale, rotation).\n",
        "    \"\"\"\n",
        "    vertex = ply_data['vertex']\n",
        "    x = np.array(vertex['x'])\n",
        "    y = np.array(vertex['y'])\n",
        "    z = np.array(vertex['z'])\n",
        "\n",
        "    mask = (\n",
        "        (x >= bbox_min[0]) & (x <= bbox_max[0]) &\n",
        "        (y >= bbox_min[1]) & (y <= bbox_max[1]) &\n",
        "        (z >= bbox_min[2]) & (z <= bbox_max[2])\n",
        "    )\n",
        "\n",
        "    n_inside = mask.sum()\n",
        "    n_total  = len(x)\n",
        "    print(f\"   Gaussians inside bbox  : {n_inside:,} / {n_total:,}  ({100*n_inside/n_total:.1f}%)\")\n",
        "\n",
        "    if n_inside == 0:\n",
        "        print(\"‚ö†Ô∏è  WARNING: No Gaussians found in this bounding box.\")\n",
        "        print(\"   ‚Üí Widen your bbox_min / bbox_max values.\")\n",
        "        return False\n",
        "\n",
        "    # Reconstruct filtered vertex data preserving all properties\n",
        "    props = vertex.data[mask]\n",
        "    filtered_element = PlyElement.describe(props, 'vertex')\n",
        "    PlyData([filtered_element], text=False).write(output_path)\n",
        "    return True\n",
        "\n",
        "\n",
        "print(f\"üîÑ Cropping point cloud...\")\n",
        "print(f\"   bbox_min = {bbox_min.tolist()}\")\n",
        "print(f\"   bbox_max = {bbox_max.tolist()}\")\n",
        "print()\n",
        "\n",
        "success = crop_gaussians(raw_ply, bbox_min, bbox_max, output_path)\n",
        "\n",
        "if success:\n",
        "    out_mb = os.path.getsize(output_path) / (1024*1024)\n",
        "    orig_mb = os.path.getsize(point_cloud_path) / (1024*1024)\n",
        "    print(f\"\\n‚úÖ Cropped model saved: {output_path}\")\n",
        "    print(f\"   Original size : {orig_mb:.2f} MB\")\n",
        "    print(f\"   Cropped size  : {out_mb:.2f} MB\")\n",
        "    print(f\"   Reduction     : {100*(orig_mb-out_mb)/orig_mb:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_WVyO5G78jR"
      },
      "outputs": [],
      "source": [
        "# ‚ïê‚ïê Iterate: try multiple bounding boxes and compare ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# Run this cell repeatedly with different values to compare crops\n",
        "\n",
        "def quick_crop_stats(ply_data, bbox_min, bbox_max, label=\"\"):\n",
        "    \"\"\"Quickly show how many Gaussians fall inside a bounding box.\"\"\"\n",
        "    vertex = ply_data['vertex']\n",
        "    x = np.array(vertex['x'])\n",
        "    y = np.array(vertex['y'])\n",
        "    z = np.array(vertex['z'])\n",
        "    mask = (\n",
        "        (x >= bbox_min[0]) & (x <= bbox_max[0]) &\n",
        "        (y >= bbox_min[1]) & (y <= bbox_max[1]) &\n",
        "        (z >= bbox_min[2]) & (z <= bbox_max[2])\n",
        "    )\n",
        "    n = mask.sum()\n",
        "    pct = 100 * n / len(x)\n",
        "    print(f\"  [{label}]  {n:>8,} Gaussians  ({pct:5.1f}%)  \"\n",
        "          f\"bbox {bbox_min.tolist()} ‚Üí {bbox_max.tolist()}\")\n",
        "\n",
        "print(\"Bounding box comparison:\")\n",
        "print(\"-\" * 80)\n",
        "quick_crop_stats(raw_ply, p_10, p_90, \"tight (10-90%)\")\n",
        "quick_crop_stats(raw_ply, p_05, p_95, \"medium (5-95%)\")\n",
        "quick_crop_stats(raw_ply, p_mean - p_std, p_mean + p_std, \"mean¬±1std\")\n",
        "quick_crop_stats(raw_ply, p_mean - 2*p_std, p_mean + 2*p_std, \"mean¬±2std\")\n",
        "quick_crop_stats(raw_ply, p_min, p_max, \"full scene\")\n",
        "print(\"-\" * 80)\n",
        "print(\"\\nUse these as reference, then set bbox_min/bbox_max in the cell above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeAZxFlF78jR"
      },
      "source": [
        "---\n",
        "## Step 8: Visualise Cropped Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApddErvv78jR"
      },
      "outputs": [],
      "source": [
        "# Load and visualise cropped model\n",
        "if os.path.exists(output_path):\n",
        "    cropped_positions, _ = load_ply_numpy(output_path)\n",
        "    M = len(cropped_positions)\n",
        "\n",
        "    sample_m = min(15000, M)\n",
        "    idx2 = np.random.choice(M, sample_m, replace=False)\n",
        "    cpts = cropped_positions[idx2]\n",
        "    z_c = (cpts[:, 2] - cpts[:, 2].min()) / (np.ptp(cpts[:, 2]) + 1e-8)\n",
        "\n",
        "    fig = plt.figure(figsize=(14, 4))\n",
        "    views = [(20, 45, 'Perspective'), (0, 0, 'XY top'), (0, 90, 'XZ front'), (90, 0, 'YZ side')]\n",
        "\n",
        "    for k, (elev, azim, title) in enumerate(views):\n",
        "        ax = fig.add_subplot(1, 4, k+1, projection='3d')\n",
        "        ax.scatter(cpts[:,0], cpts[:,1], cpts[:,2],\n",
        "                   c=z_c, cmap='viridis', s=0.5, alpha=0.7)\n",
        "        ax.view_init(elev=elev, azim=azim)\n",
        "        ax.set_title(title, color='white', fontsize=10)\n",
        "        ax.set_facecolor('#1a1a2e')\n",
        "        ax.tick_params(colors='gray', labelsize=6)\n",
        "\n",
        "    fig.patch.set_facecolor('#0f0f1a')\n",
        "    plt.suptitle(f'Cropped Object Preview ({M:,} Gaussians)',\n",
        "                 color='white', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/cropped_preview.png', dpi=120, bbox_inches='tight',\n",
        "                facecolor='#0f0f1a')\n",
        "    plt.show()\n",
        "    print(\"‚úÖ Cropped preview saved to /content/cropped_preview.png\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Cropped file not found. Run Step 7 first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qyQ5H9s78jR"
      },
      "source": [
        "---\n",
        "## Step 9: Download All Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1783db00"
      },
      "source": [
        "print(\"## Summary of Pipeline Parameters for Conference Paper\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# 1. Input Data Characteristics\n",
        "print(\"### 1. Input Data Characteristics\")\n",
        "print(f\"- Input Video Filename: {video_filename}\")\n",
        "print(f\"- Extracted Frames Per Second (FPS): {fps}\")\n",
        "print(f\"- Total Number of Extracted Frames: {len(frames)}\")\n",
        "\n",
        "# 2. COLMAP Reconstruction Metrics\n",
        "print(\"\\n### 2. COLMAP Reconstruction Metrics\")\n",
        "print(f\"- Initial Number of 3D Points (from COLMAP): {N:,} Gaussians\")\n",
        "# Note: Exact number of reconstructed cameras and COLMAP time need to be extracted from COLMAP logs/output if precise values are required.\n",
        "\n",
        "# 3. Gaussian Splatting Training Details\n",
        "print(\"\\n### 3. Gaussian Splatting Training Details\")\n",
        "print(f\"- Number of Training Iterations: {iterations:,}\")\n",
        "print(f\"- Output Model Directory: {output_model_dir}\")\n",
        "# Note: Final Loss Values (L1, PSNR) and training time need to be extracted from training logs/output.\n",
        "\n",
        "# 4. Cropping Parameters and Results\n",
        "print(\"\\n### 4. Cropping Parameters and Results\")\n",
        "print(f\"- Bounding Box Min (X, Y, Z): {bbox_min.tolist()}\")\n",
        "print(f\"- Bounding Box Max (X, Y, Z): {bbox_max.tolist()}\")\n",
        "print(f\"- Number of Cropped Gaussians: {M:,}\")\n",
        "if 'orig_mb' in locals() and 'out_mb' in locals():\n",
        "    print(f\"- Original Model Size: {orig_mb:.2f} MB\")\n",
        "    print(f\"- Cropped Model Size: {out_mb:.2f} MB\")\n",
        "    print(f\"- Percentage of Gaussians Retained: {100*M/N:.1f}%\")\n",
        "    print(f\"- Storage Reduction: {100*(orig_mb-out_mb)/orig_mb:.1f}%\")\n",
        "\n",
        "# 5. Qualitative Visualizations\n",
        "print(\"\\n### 5. Qualitative Visualizations Generated\")\n",
        "print(f\"- Axis Distribution Histogram: /content/axis_distribution.png\")\n",
        "print(f\"- Full Scene 3D Preview: /content/point_cloud_3d_preview.png\")\n",
        "print(f\"- Cropped Object Preview: /content/cropped_preview.png\")\n",
        "\n",
        "# 6. System Specifications\n",
        "print(\"\\n### 6. System Specifications\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"- GPU Used: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"- GPU Used: Not available or not detected\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hi1kLgX78jR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "def safe_download(path, label):\n",
        "    if os.path.exists(path):\n",
        "        size_mb = os.path.getsize(path) / (1024*1024)\n",
        "        print(f\"üì• Downloading {label} ({size_mb:.2f} MB)...\")\n",
        "        files.download(path)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  {label} not found at {path}\")\n",
        "\n",
        "# Download full point cloud\n",
        "safe_download(point_cloud_path, \"Full Point Cloud\")\n",
        "\n",
        "# Download cropped object\n",
        "safe_download(output_path, \"Cropped Object\")\n",
        "\n",
        "# Download visualisation images\n",
        "safe_download('/content/axis_distribution.png',      \"Axis Distribution Plot\")\n",
        "safe_download('/content/point_cloud_3d_preview.png', \"Full Scene 3D Preview\")\n",
        "safe_download('/content/cropped_preview.png',        \"Cropped Object Preview\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdbUUl5E78jR"
      },
      "source": [
        "---\n",
        "## üìå Reference: How to Find the Perfect Bounding Box\n",
        "\n",
        "### Method 1 ‚Äî Statistics-based (easiest)\n",
        "Use the table printed in **Step 6** as a guide:\n",
        "- If your object is the **main subject** of the scene ‚Üí use **10th‚Äì90th percentile** range\n",
        "- If there is significant background ‚Üí use **25th‚Äì75th percentile** to focus on the core\n",
        "- If the scene has outlier noise ‚Üí ignore Min/Max, trust percentiles instead\n",
        "\n",
        "### Method 2 ‚Äî Histogram-based (accurate)\n",
        "Look at the axis histograms:\n",
        "- Find the **dense cluster** in each axis ‚Äî that's your object\n",
        "- The sparse tails are usually background/noise\n",
        "- Set `bbox_min[axis]` = left edge of the cluster, `bbox_max[axis]` = right edge\n",
        "\n",
        "### Method 3 ‚Äî 3D view-based (visual)\n",
        "Look at the 4 3D views and estimate where the object is spatially:\n",
        "- `XY top view` ‚Üí set X and Y bounds\n",
        "- `XZ front view` ‚Üí set X and Z bounds  \n",
        "- `YZ side view` ‚Üí set Y and Z bounds\n",
        "\n",
        "### Method 4 ‚Äî Iterative refinement (most precise)\n",
        "1. Run `quick_crop_stats()` cell with progressively tighter boxes\n",
        "2. A good crop keeps **20‚Äì60%** of total Gaussians (more = more context, less = cleaner)\n",
        "3. Visually inspect each crop using Step 8\n",
        "\n",
        "### ‚ö†Ô∏è Common Pitfalls\n",
        "| Problem | Fix |\n",
        "|---|---|\n",
        "| 0 Gaussians in bbox | Your values are outside the scene range ‚Äî check Step 6 stats |\n",
        "| Crop includes background | Tighten bbox_min/max further toward the mean |\n",
        "| Object is cut off | Expand bbox in the axis where it's cut |\n",
        "| Y-axis is flipped | Try negating Y values (common in some COLMAP outputs) |\n",
        "\n",
        "### üî≠ View in a 3D Gaussian Splatting Viewer\n",
        "Open your `.ply` file in:\n",
        "- [SuperSplat](https://playcanvas.com/supersplat/editor) (browser-based, free)\n",
        "- [Luma AI Viewer](https://lumalabs.ai) (browser-based)\n",
        "- [3D Gaussian Splatting Viewer](https://github.com/antimatter15/splat) (local)\n",
        "\n",
        "These viewers will show you the actual rendered scene and let you visually determine better bounding box coordinates."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}